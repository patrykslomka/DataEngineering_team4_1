{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:14:40.715500Z",
     "start_time": "2024-10-11T10:14:31.223794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "! pip3 install --user --no-cache-dir --upgrade \"kfp>2\" \"google-cloud-pipeline-components>2\" \\\n",
    "                                        google-cloud-aiplatform"
   ],
   "id": "892d94ced0869014",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp>2 in c:\\users\\patry\\appdata\\roaming\\python\\python312\\site-packages (2.9.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Ignored the following versions that require a different python version: 2.0.0 Requires-Python >=3.7.0,<3.12.0; 2.0.0-beta.14 Requires-Python >=3.7.0,<3.12.0; 2.0.0-beta.17 Requires-Python >=3.7.0,<3.12.0; 2.0.0-rc.1 Requires-Python >=3.7.0,<3.12.0; 2.0.0-rc.2 Requires-Python >=3.7.0,<3.12.0; 2.0.0b15 Requires-Python >=3.7.0,<3.12.0; 2.0.0b16 Requires-Python >=3.7.0,<3.12.0; 2.0.0b2 Requires-Python >=3.7.0,<3.12.0; 2.0.0b3 Requires-Python >=3.7.0,<3.12.0; 2.0.0b4 Requires-Python >=3.7.0,<3.12.0; 2.0.0b5 Requires-Python >=3.7.0,<3.12.0; 2.0.1 Requires-Python >=3.7.0,<3.12.0; 2.1.0 Requires-Python >=3.7.0,<3.12.0; 2.1.1 Requires-Python >=3.7.0,<3.12.0; 2.1.2 Requires-Python >=3.7.0,<3.12.0; 2.1.3 Requires-Python >=3.7.0,<3.12.0; 2.10.0 Requires-Python >=3.7.0,<3.12.0; 2.11.0 Requires-Python <3.12.0,>=3.7.0; 2.12.0 Requires-Python <3.12.0,>=3.7.0; 2.13.0 Requires-Python <3.12.0,>=3.7.0; 2.13.1 Requires-Python <3.12.0,>=3.7.0; 2.14.0 Requires-Python <3.12.0,>=3.8.0; 2.14.1 Requires-Python <3.12.0,>=3.8.0; 2.15.0 Requires-Python <3.12.0,>=3.8.0; 2.16.0 Requires-Python <3.12.0,>=3.8.0; 2.16.1 Requires-Python <3.12.0,>=3.8.0; 2.17.0 Requires-Python <3.12.0,>=3.8.0; 2.2.0 Requires-Python >=3.7.0,<3.12.0; 2.3.0 Requires-Python >=3.7.0,<3.12.0; 2.3.1 Requires-Python >=3.7.0,<3.12.0; 2.4.0 Requires-Python >=3.7.0,<3.12.0; 2.4.1 Requires-Python >=3.7.0,<3.12.0; 2.5.0 Requires-Python >=3.7.0,<3.12.0; 2.6.0 Requires-Python >=3.7.0,<3.12.0; 2.7.0 Requires-Python >=3.7.0,<3.12.0; 2.8.0 Requires-Python >=3.7.0,<3.12.0; 2.9.0 Requires-Python >=3.7.0,<3.12.0\n",
      "ERROR: Could not find a version that satisfies the requirement google-cloud-pipeline-components>2 (from versions: 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.1.6, 0.1.7, 0.1.8.dev0, 0.1.8, 0.1.9.dev0, 0.1.9, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.3.0, 0.3.1, 1.0.dev2, 1.0.0, 1.0.1, 1.0.2, 1.0.3, 1.0.4, 1.0.5.dev0, 1.0.5, 1.0.6, 1.0.7, 1.0.8, 1.0.9, 1.0.10, 1.0.11, 1.0.12, 1.0.13, 1.0.14, 1.0.15, 1.0.16, 1.0.17, 1.0.18, 1.0.19, 1.0.20, 1.0.21, 1.0.22, 1.0.23, 1.0.24, 1.0.25, 1.0.26, 1.0.27, 1.0.28, 1.0.29, 1.0.30, 1.0.31, 1.0.32, 1.0.33, 1.0.34, 1.0.35, 1.0.36, 1.0.37, 1.0.38, 1.0.39, 1.0.40, 1.0.41, 1.0.42, 1.0.43, 1.0.44, 1.0.45, 2.0.0b0, 2.0.0b1)\n",
      "ERROR: No matching distribution found for google-cloud-pipeline-components>2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:14:45.801579Z",
     "start_time": "2024-10-11T10:14:45.789056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# restart kernel\n",
    "import os\n",
    "\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ],
   "id": "990eab1ceb55dd8e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:14:59.119999Z",
     "start_time": "2024-10-11T10:14:53.992845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! pip3 freeze | grep aiplatform\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ],
   "id": "51eb64b820bf03a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 2.9.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'grep' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "google_cloud_pipeline_components version: 1.0.33\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-11T10:15:28.391077Z",
     "start_time": "2024-10-11T10:15:06.280822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import kfp\n",
    "import typing\n",
    "from typing import Dict\n",
    "from typing import NamedTuple\n",
    "from kfp import dsl\n",
    "from kfp.dsl import (Artifact,\n",
    "                        Dataset,\n",
    "                        Input,\n",
    "                        Model,\n",
    "                        Output,\n",
    "                        Metrics,\n",
    "                        ClassificationMetrics,\n",
    "                        component, \n",
    "                        OutputPath, \n",
    "                        InputPath)\n",
    "import google.cloud.aiplatform as aip\n",
    "from google_cloud_pipeline_components.v1.model import ModelUploadOp\n",
    "from google_cloud_pipeline_components.v1.endpoint import (EndpointCreateOp,ModelDeployOp)\n",
    "from google_cloud_pipeline_components.types import artifact_types"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:15:48.561311Z",
     "start_time": "2024-10-11T10:15:48.542294Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROJECT_ID = \"hip-lightning-435508-s1\"  # Replace with your Google Cloud project ID\n",
    "REGION = \"us-central1\"  # Adjust the region as needed\n",
    "PIPELINE_ROOT = \"gs://mlops_team4_de2024\"  # Replace with your GCS bucket URI\n"
   ],
   "id": "8512bd11efb06fa2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:15:52.211946Z",
     "start_time": "2024-10-11T10:15:52.182522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Train Test Split\n",
    "@dsl.component(\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn==1.3.2\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def train_test_split(dataset: Input[Dataset], dataset_train: Output[Dataset], dataset_test: Output[Dataset]):\n",
    "    '''Splits the California housing dataset into training and testing sets.'''\n",
    "    import pandas as pd\n",
    "    import logging \n",
    "    import sys\n",
    "    from sklearn.model_selection import train_test_split as tts\n",
    "\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO) \n",
    "    \n",
    "    # Load data from the dataset\n",
    "    alldata = pd.read_csv(dataset.path, index_col=None)\n",
    "    train, test = tts(alldata, test_size=0.3)\n",
    "    \n",
    "    # Save the splits\n",
    "    train.to_csv(dataset_train.path + \".csv\" , index=False, encoding='utf-8-sig')\n",
    "    test.to_csv(dataset_test.path + \".csv\" , index=False, encoding='utf-8-sig')\n"
   ],
   "id": "1dda90478c019b4f",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:15:56.444667Z",
     "start_time": "2024-10-11T10:15:56.425730Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Training Component\n",
    "@dsl.component(\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn==1.3.2\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def train_regression_model(features: Input[Dataset], model: Output[Model]):\n",
    "    '''Train a regression model using Linear Regression.'''\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import LinearRegression        \n",
    "    import pickle \n",
    "    \n",
    "    # Load the training data\n",
    "    data = pd.read_csv(features.path+\".csv\")\n",
    "    \n",
    "    # Train a Linear Regression model\n",
    "    model_lr = LinearRegression()\n",
    "    X = data.drop('median_house_value', axis=1)  # We can change 'median_house_value' to our target column name\n",
    "    y = data['median_house_value']\n",
    "    model_lr.fit(X, y)\n",
    "\n",
    "    # Save the model to the specified path\n",
    "    file_name = model.path + f\".pkl\"\n",
    "    with open(file_name, 'wb') as file:  \n",
    "        pickle.dump(model_lr, file)   \n"
   ],
   "id": "7964c01b19ff399b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:16:00.003265Z",
     "start_time": "2024-10-11T10:15:59.990502Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Model Evaluation\n",
    "@dsl.component(\n",
    "    packages_to_install=[\"pandas\", \"scikit-learn==1.3.2\", \"numpy\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def evaluate_model(\n",
    "    test_set: Input[Dataset],\n",
    "    model: Input[Model],\n",
    "    metrics: Output[Metrics]\n",
    "):\n",
    "    '''Evaluate the trained regression model.'''\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "    import numpy as np\n",
    "\n",
    "    # Load test data and model\n",
    "    data = pd.read_csv(test_set.path + \".csv\")\n",
    "    X_test = data.drop('median_house_value', axis=1)\n",
    "    y_test = data['median_house_value']\n",
    "    \n",
    "    model_file = model.path + \".pkl\"\n",
    "    loaded_model = pickle.load(open(model_file, 'rb'))\n",
    "\n",
    "    # Predictions\n",
    "    y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    # Log metrics\n",
    "    metrics.log_metric(\"mean_absolute_error\", mae)\n",
    "    metrics.log_metric(\"root_mean_squared_error\", rmse)\n"
   ],
   "id": "2a5831123f80d0c3",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-11T10:17:11.702993Z",
     "start_time": "2024-10-11T10:17:11.691420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dsl.component(\n",
    "    packages_to_install=[\"google-cloud-storage\"],\n",
    "    base_image=\"python:3.10.7-slim\"\n",
    ")\n",
    "def upload_model_to_gcs(project_id: str, model_repo: str, model: Input[Model]):\n",
    "    '''upload model to gsc'''\n",
    "    from google.cloud import storage   \n",
    "    import logging \n",
    "    import sys\n",
    "    \n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)    \n",
    "  \n",
    "    # upload the model to GCS\n",
    "    client = storage.Client(project=project_id)\n",
    "    bucket = client.bucket(model_repo)\n",
    "    blob = bucket.blob(str(model.metadata[\"algo\"]) + '_model' + str(model.metadata[\"file_type\"])) \n",
    "    blob.upload_from_filename(model.path + str(model.metadata[\"file_type\"]))       \n",
    "    \n",
    "    print(\"Saved the model to GCP bucket : \" + model_repo)"
   ],
   "id": "2867333bc705bded",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
